# TODO: remove dashed lines (is to highlight what is still to change!)
"team_name": "REAL" # Your team name
"eval_method": ["reward"] # mcqa, reward, rag, compression
"task_type": "causal_lm" # causal_lm, seq2seq
"policy_model_path": "aerdna/gemma-dpo-stem-real" # Your path to the final checkpoint
"reference_model_path": "google/gemma-2b" # The repo id of your pretrained reference model
"quantized_policy_model_path": "./checkpoints/best_model_quantized/" # Your path to the final quantized checkpoint
"rag_policy_model_path": "./checkpoints/best_model_rag/" # Your path to the final RAG checkpoint
"test_data_path": "../data/dpo/epfl_test_data_100.json" # Your path to the test data
"dpo_model_args": null # Put any model arguments required to load your DPO model below
"rag_model_args": # Put any model arguments required to load your rag model belo
